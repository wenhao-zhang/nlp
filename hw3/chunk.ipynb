{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Homework: Phrasal Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Group: Wisefish \n",
    "\n",
    "* Wenhao Zhang, wenhaoz \n",
    "* Graeme Milne, gmilne \n",
    "* Mitchell McCormack, mmccorma\n",
    "* Jonathan Lo, jcl60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Development process\n",
    "\n",
    "In order to be able to best use knowledge and time, we decided to work together at the same time to understand and implement the base algorithm.  \n",
    "So we got togther in a lecture room for a few hours and worked together to understand the actual algorithm, the expected data structures to contain the data, and implement at least a baseline functional algorithm. \n",
    "\n",
    "The result of that session was a baseline implementation of the algorithm, but with some remaining issues in how we updated the feature vector at each epoch (described below).  \n",
    "After some continued adjustments and helping each other continue to understand how the algorithm worked, we arrived at our final implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The baseline perceptron algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def perc_train(train_data, tagset, numepochs):\n",
      "    \"\"\"\n",
      "    Perceptron training algorithm\n",
      "\n",
      "    We run the provided training data and tagset for `numepoch` training runs over the entire training set.\n",
      "    \"\"\"\n",
      "    feat_vec = defaultdict(int)\n",
      "    z = []\n",
      "    truth = []\n",
      "    previous_error_count = 0\n",
      "\n",
      "    for i in range(numepochs):\n",
      "        final_z = []\n",
      "        final_truth = []\n",
      "        for (labeled_list, feat_list) in train_data:\n",
      "            truth = [x.split(\" \")[2] for x in labeled_list]\n",
      "            z = perc.perc_test(feat_vec, labeled_list,\n",
      "                               feat_list, tagset, tagset[0])\n",
      "\n",
      "            final_z.append(z)\n",
      "            final_truth.append(truth)\n",
      "\n",
      "            # the resulting prediction is not the same (ordered list comparison) as the truth,\n",
      "            # update the feature vector\n",
      "            if z != truth:\n",
      "                feat_vec = update_feat_vect(feat_vec, feat_list, z, truth)\n",
      "\n",
      "        error_count = count_errors(final_truth, final_z)\n",
      "        print(\"number of mistakes: \", error_count)\n",
      "\n",
      "        # We've reached the best possible result already (the current run was worse than the previous)\n",
      "        # so we exit early.\n",
      "        if i > 0 and error_count >= previous_error_count:\n",
      "            return feat_vec\n",
      "\n",
      "        previous_error_count = error_count\n",
      "\n",
      "    return feat_vec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chunk_baseline import perc_train\n",
    "\n",
    "print(inspect.getsource(perc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The averaged perceptron algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def perc_train(train_data, tagset, numepochs):\n",
      "\n",
      "    \"\"\"\n",
      "    Perceptron training algorithm\n",
      "\n",
      "    We run the provided training data and tagset for `numepoch` training runs over the entire training set.\n",
      "    \"\"\"   \n",
      "\n",
      "    feat_vec = defaultdict(int)\n",
      "    avg_feat_vec = defaultdict(int)\n",
      "    z = []\n",
      "    truth = []\n",
      "    last_update = {}\n",
      "    train_data_index = 0\n",
      "    train_data_size = len(train_data)\n",
      "\n",
      "    previous_error_count = 0\n",
      "\n",
      "    for i in range(numepochs):\n",
      "        final_z = []\n",
      "        final_truth = []\n",
      "        for (labeled_list, feat_list) in train_data:\n",
      "            truth = [x.split(\" \")[2] for x in labeled_list]\n",
      "            z = perc.perc_test(feat_vec, labeled_list,\n",
      "                               feat_list, tagset, tagset[0])\n",
      "\n",
      "            final_z.append(z)\n",
      "            final_truth.append(truth)\n",
      "\n",
      "            if z != truth:\n",
      "                feat_vec, avg_feat_vec, last_update = update_feat_vect(feat_vec, avg_feat_vec, i, numepochs,\n",
      "                                            last_update, train_data_index, train_data_size, feat_list, z, truth)\n",
      "\n",
      "            train_data_index += 1\n",
      "\n",
      "        error_count = count_errors(final_truth, final_z)\n",
      "        print(\"number of mistakes: \", error_count)\n",
      "\n",
      "        if i > 0 and error_count >= previous_error_count:\n",
      "            break\n",
      "\n",
      "        previous_error_count = error_count\n",
      "    # pp.pprint(feat_vec)\n",
      "\n",
      "    return_value = {}\n",
      "\n",
      "    for key, value in  avg_feat_vec.items():\n",
      "        return_value[key]  = value/(train_data_size * numepochs)\n",
      "    \n",
      "    # please limit the number of iterations of training to n iterations\n",
      "    return return_value\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chunk import perc_train\n",
    "\n",
    "print(inspect.getsource(perc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Updating the feature vector(Baseline)\n",
    "\n",
    "If the predicted chunking labels for a given sentence do not match the training data values then the feature vector is updated using the `update_feat_vect` function. If an element's predicted tag is the same as in the true set then it is skipped over. In the mispredicted case, the incorrect tag is punished and the correct one is rewarded. Example: \n",
    "\n",
    "* Predicted: `NN -> B-NP`\n",
    "* Truth:     `NN -> B-PP`\n",
    "* `(U14:NN, B-PP)`: (value += 1)\n",
    "* `(U14:NN, B-NP)`: (value -= 1)\n",
    "\n",
    "In our earliest implementations we made a mistake in our punish and reward logic such that a feature vector involved rewarding correct prediction and punishing in the incorrect one.\n",
    "```\n",
    "if prediction != truth: \n",
    "    (feature_function, prediction) - 1 \n",
    "else: \n",
    "    (feature_function, truth)  + 1\n",
    "```\n",
    "\n",
    "This small detail with a large impact was easily overlooked at first. However, after a much closer reading of the assignment outline and baseline algorithm description, the error was discovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def update_feat_vect(feat_vec, feat_list, z, truth):\n",
      "    \"\"\"\n",
      "    Update the provided weighting feature vector based on the given feature list, predicted output, and the truth reference.\n",
      "    \"\"\"\n",
      "    for i in range(len(z)):\n",
      "        if z[i] != truth[i]:\n",
      "\n",
      "            # Penalize the incorrect features and reward the actual correct features\n",
      "            for j in range(19):\n",
      "                feat_vec[(feat_list[20*i+j], z[i])] -= 1\n",
      "                feat_vec[(feat_list[20*i+j], truth[i])] += 1\n",
      "\n",
      "            for j in range(2):\n",
      "                if (i == 0 and j == 0) or (i == len(z) - 1 and j == 1):\n",
      "                    continue\n",
      "\n",
      "                feat_vec[(feat_list[20*i+19] + \":\" + z[i-1+j], z[i+j])] -= 1\n",
      "                feat_vec[(feat_list[20*i+19] + \":\" + truth[i-1+j], truth[i+j])] += 1\n",
      "\n",
      "    return feat_vec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chunk_baseline import update_feat_vect\n",
    "\n",
    "print(inspect.getsource(update_feat_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the feature vector(Average perceptron)\n",
    "\n",
    "To improve upon the baseline, we implemented the algorithim from Sarkar 2011 page 38. The averaged perceptron algorithim averages the weights. During each interval we update the weights by pushing the features that are not in the truth and rewarding the feature in the truth. We then updated the average weight feature vector. We store the average features in a list called avg_feat_vec and the not averaged features in a list called feat_vec. To update the average weights. We multiple the value of a feature in feat_vc and then store it in avg_feat_vec with the same key. The updating is lazying updating. We only update those weights that need to updated instead of all the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def update_feat_vect(feat_vec, avg_feat_vec, iter_num, epoch, last_update, train_data_index, train_data_size, feat_list, z, truth):\n",
      "\n",
      "    \"\"\"\n",
      "    Update the provided weighting feature vector based on the given feature list, predicted output, and the truth reference.\n",
      "    \"\"\"\n",
      "\n",
      "    if iter_num != epoch-1 or train_data_index != train_data_size-1:\n",
      "        for i in range(len(z)):\n",
      "            if z[i] != truth[i]:\n",
      "                for j in range(19):\n",
      "                    yprime = (feat_list[20*i+j], z[i])\n",
      "                    y = (feat_list[20*i+j], truth[i])\n",
      "\n",
      "                    feat_vec[yprime] -= 1\n",
      "                    feat_vec[y] += 1\n",
      "\n",
      "                    if yprime in last_update:\n",
      "                        scale = iter_num * train_data_size + train_data_index - last_update[yprime][1] * train_data_size - last_update[yprime][0]\n",
      "                        avg_feat_vec[yprime] += scale * feat_vec[yprime]\n",
      "                    else:\n",
      "                        avg_feat_vec[yprime] -= 1\n",
      "                        \n",
      "                    \n",
      "                    if y in last_update:\n",
      "                        scale = iter_num * train_data_size + train_data_index - last_update[y][1] * train_data_size - last_update[y][0]\n",
      "                        avg_feat_vec[y] += scale * feat_vec[y]\n",
      "                    else:\n",
      "                        avg_feat_vec[y] += 1\n",
      "\n",
      "                    last_update[yprime] = (train_data_index,iter_num)\n",
      "                    last_update[y] = (train_data_index,iter_num)\n",
      "\n",
      "                for j in range(2):\n",
      "\n",
      "                    if (i == 0 and j == 0) or (i == len(z) - 1 and j == 1):\n",
      "                        continue\n",
      "\n",
      "                    yprime = (feat_list[20*i+19] + \":\" + z[i-1+j], z[i+j])\n",
      "                    y = (feat_list[20*i+19] + \":\" + truth[i-1+j], truth[i+j])\n",
      "\n",
      "                    feat_vec[yprime] -= 1\n",
      "                    feat_vec[y] += 1\n",
      "\n",
      "                    if yprime in last_update:\n",
      "                        scale = iter_num * train_data_size + train_data_index - last_update[yprime][1] * train_data_size - last_update[yprime][0]\n",
      "                        avg_feat_vec[yprime] += scale * feat_vec[yprime]\n",
      "                    else:\n",
      "                        avg_feat_vec[yprime] -= 1\n",
      "                        \n",
      "                    \n",
      "                    if y in last_update:\n",
      "                        scale = iter_num * train_data_size + train_data_index - last_update[y][1] * train_data_size - last_update[y][0]\n",
      "                        avg_feat_vec[y] += scale * feat_vec[y]\n",
      "                    else:\n",
      "                        avg_feat_vec[y] += 1 \n",
      "\n",
      "                    last_update[yprime] = (train_data_index, iter_num)\n",
      "                    last_update[y] = (train_data_index, iter_num)\n",
      "                    \n",
      "    else:\n",
      "        for key, value in last_update.items():\n",
      "            scale_factor = epoch * train_data_size + train_data_size - value[1] * train_data_size - value[0]\n",
      "            avg_feat_vec[key] = scale_factor * feat_vec[key]\n",
      "\n",
      "        for i in range(len(z)):\n",
      "            if z[i] != truth[i]:\n",
      "                for j in range(19):\n",
      "                    yprime = (feat_list[20*i+j], z[i])\n",
      "                    y = (feat_list[20*i+j], truth[i])\n",
      "\n",
      "                    feat_vec[yprime] -= 1\n",
      "                    feat_vec[y] += 1\n",
      "\n",
      "                    if yprime not in last_update:\n",
      "                        avg_feat_vec[yprime] -= 1\n",
      "                        \n",
      "                    \n",
      "                    if y not in last_update:\n",
      "                        avg_feat_vec[y] += 1\n",
      "\n",
      "                for j in range(2):\n",
      "\n",
      "                    if (i == 0 and j == 0) or (i == len(z) - 1 and j == 1):\n",
      "                        continue\n",
      "\n",
      "                    yprime = (feat_list[20*i+19] + \":\" + z[i-1+j], z[i+j])\n",
      "                    y = (feat_list[20*i+19] + \":\" + truth[i-1+j], truth[i+j])\n",
      "\n",
      "                    feat_vec[yprime] -= 1\n",
      "                    feat_vec[y] += 1\n",
      "\n",
      "                    if yprime not in last_update:\n",
      "                        avg_feat_vec[yprime] -= 1\n",
      "                        \n",
      "                    \n",
      "                    if y not in last_update:\n",
      "                        avg_feat_vec[y] += 1 \n",
      "\n",
      "    return feat_vec, avg_feat_vec, last_update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chunk import update_feat_vect\n",
    "\n",
    "print(inspect.getsource(update_feat_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluating errors at each epoch\n",
    "\n",
    "In the `count_errors` function, the total number of mispredicted output labels are counted in each epoch. By counting the number of errors occuring we are able to see the trend over time as the weights are adjusted and the model is trained.\n",
    "\n",
    "The weight adjustments should always result in an improved prediction of the output labels and decreasing error count, converging to the best weighting function vector. If the number of errors ever increases, we know we have reached the best weightings possible.\n",
    "\n",
    "After each epoch, the number of errors is compared to the previous epoch's count. If the number of errors is greater than or equal to the previous epoch, the algorithm stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_errors(test, truth):\n",
      "    \"\"\"\n",
      "    Helper to count the amount of errors between the predicted output and the known truth reference.\n",
      "    \"\"\"\n",
      "    count = 0\n",
      "    for idx, item in enumerate(test):\n",
      "        if item != truth[idx]:\n",
      "            count += 1\n",
      "    return count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chunk import count_errors\n",
    "print(inspect.getsource(count_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Results of our Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE:** For performance, we are executing these commands in a separate shell with `!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We run our perc_train on the specified training data and write the resulting model to the file `baseline.model`. For grading purposes, we run it on the `train.txt.gz` / `train.feats.gz` data set for 10 iterations / epochs.\n",
    "\n",
    "After each epoch, we output the number of mistakes that were made by the perceptron using the feature vector provided to it. As the training runs, the number of mistakes should decrease, and stop when we detect the best possible training output or we reach the number of epochs specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data ...\n",
      "done.\n",
      "number of mistakes:  5630\n",
      "number of mistakes:  4019\n",
      "number of mistakes:  3059\n",
      "number of mistakes:  2332\n",
      "number of mistakes:  1877\n",
      "number of mistakes:  1448\n",
      "number of mistakes:  1201\n",
      "number of mistakes:  1046\n",
      "number of mistakes:  836\n",
      "number of mistakes:  711\n"
     ]
    }
   ],
   "source": [
    "! python3 chunk.py -m data/baseline.model -t data/tagset.txt -i data/train.txt.gz -f data/train.feats.gz -e 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now take our trained and saved model to use on a testing data set (`dev.txt` and `dev.feats`). \n",
    "\n",
    "We save the output predictions for the testing dataset and save it to the file `output`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data ...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "! python3 perc.py -m data/baseline.model -t data/tagset.txt -i data/dev.txt -f data/dev.feats > output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally we take the output of our test predictions and feed it to `score_chunks.py` to evaluate.\n",
    "\n",
    "This program takes the given output from `perc.py` and evaluates it against the gold reference `reference500.txt`, which is for `dev.txt`.\n",
    "\n",
    "The final line of output contains the evaluation, which from our test runs is an F1 score of `92.73`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 500 sentences with 10375 tokens and 5783 phrases; found phrases: 5771; correct phrases: 5357\r\n",
      "             ADJP: precision:  72.73%; recall:  72.73%; F1:  72.73; found:     99; correct:     99\r\n",
      "             ADVP: precision:  76.12%; recall:  75.74%; F1:  75.93; found:    201; correct:    202\r\n",
      "            CONJP: precision: 100.00%; recall:  60.00%; F1:  75.00; found:      3; correct:      5\r\n",
      "             INTJ: precision:   0.00%; recall:   0.00%; F1:   0.00; found:      0; correct:      1\r\n",
      "               NP: precision:  93.82%; recall:  93.29%; F1:  93.55; found:   3009; correct:   3026\r\n",
      "               PP: precision:  96.29%; recall:  97.79%; F1:  97.03; found:   1240; correct:   1221\r\n",
      "              PRT: precision:  77.78%; recall:  63.64%; F1:  70.00; found:     18; correct:     22\r\n",
      "             SBAR: precision:  80.56%; recall:  81.31%; F1:  80.93; found:    108; correct:    107\r\n",
      "               VP: precision:  92.50%; recall:  91.91%; F1:  92.20; found:   1093; correct:   1100\r\n",
      "accuracy:  95.07%; precision:  92.83%; recall:  92.63%; F1:  92.73\r\n",
      "Score: 92.73\r\n"
     ]
    }
   ],
   "source": [
    "! python3 score_chunks.py -t output -r data/reference500.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
