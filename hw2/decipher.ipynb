{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Homework: Decipherment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Group: wisefish\n",
    "\n",
    "#### Wenhao Zhang, wenhaoz\n",
    "#### Graeme Milne, gmilne \n",
    "#### Mitchell McCormack, mmccorma \n",
    "#### Jonathan Lo, jcl60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# IPython autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports and setup\n",
    "from hw2_helpers import read_file, get_statistics\n",
    "import pprint\n",
    "\"\"\"\n",
    "PrettyPrinter for output\n",
    "\"\"\"\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we read in files that are necessary for decipherment.\n",
    "\n",
    "`cipher` is the ciphertext that we would like to decode.  \n",
    "`plaintext` is data about the English language. The data used here is a dataset containing all lowercase letters, with no whitespace, no numbers, and no symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The function `get_statistics` obtains some statistics that are needed in our decipherment process.\n",
    "\n",
    "For the cipher, we need the length, frequency of characters, and vocab in the cipher text.\n",
    "For the plaintext, we need the vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cipher_desc = get_statistics(cipher, cipher=True)\n",
    "pp.pprint(cipher_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plaintext description\n",
    "plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "pp.pprint(plaintxt_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_mappings(hypo, mappings):\n",
    "    \"\"\"\n",
    "    Flattens and collects mappings from the partial hypothesis into a list\n",
    "    \"\"\"\n",
    "    if hypo:\n",
    "        if isinstance(hypo[len(hypo)-1], tuple):\n",
    "            mappings.append(hypo[len(hypo)-1])\n",
    "        if isinstance(hypo[0], tuple):\n",
    "            return extract_mappings(hypo[0],mappings)\n",
    "    else:\n",
    "        return mappings\n",
    "    \n",
    "def histogramPrune(HT, beam_size):\n",
    "    \"\"\"\n",
    "    Takes hypotheses from a beam search stage and keeps on the top `beam_size` hypotheses.\n",
    "    \"\"\"\n",
    "    sorted_HT = sorted(HT, key=lambda ht: ht[1], reverse=True)  # Order by scores (index 1), descending.\n",
    "    pruned_HT = sorted_HT[0:beam_size]  # Select the beam_size number of highest scored hypothesis.\n",
    "\n",
    "    return pruned_HT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Beam Search Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our implementation of the beam search is as described in the algorithm from the baseline paper.\n",
    "\n",
    "It goes through each ciphertext character (`Vf`) and builds up the best scoring hypotheses (`HS`) for decipherment.\n",
    "\n",
    "Our implementations of checking `EXT_LIMITS`, scoring, and determining the winning decipherment follow below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def beam_search(lm, vf, ve, ext_order, ext_limits, beam_size, cipher):\n",
    "    HS = list()\n",
    "    HT = list()\n",
    "    HS.append((tuple(),0))\n",
    "    cardinality = 0\n",
    "    while cardinality < len(vf):\n",
    "        f = ext_order[cardinality]\n",
    "        for phi in HS:\n",
    "            for e in ve:\n",
    "                phi_prime = tuple([phi, (e,f)])\n",
    "                if checkExtLimits(phi_prime, ext_limits):\n",
    "                    HT.append((phi_prime, score(lm, phi_prime, cipher)))\n",
    "        HT = histogramPrune(HT, beam_size)\n",
    "        cardinality += 1\n",
    "        HS = HT\n",
    "        HT = list()\n",
    "    return winner(HS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Checking EXT_LIMITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is used in the beam search when determining whether a given temporary hypothesis should be added to the valid hypotheses in the current search stage.\n",
    "\n",
    "The function `checkExtLimits` takes in a hypothesis (`phi_prime`) and `ext_limits`, which is the maximum number of ciphertext characters that can map to a given plaintext character.\n",
    "\n",
    "This function iterates through the mappings in the hypothesis and checks how many times each plaintext character has a mapping.\n",
    "\n",
    "If any character has more mappings than is allowed by EXT_LIMITS, the function will return `False`.\n",
    "Otherwise it will return `True` to indicate that this hypothesis has no plaintext character with more than `ext_limits` mappings to it from cipher characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkExtLimits(phi_prime, ext_limits):\n",
    "    counts = {}\n",
    "    sequence = []\n",
    "    extract_mappings(phi_prime, sequence)\n",
    "    \n",
    "    for mapping in sequence:\n",
    "        if len(mapping) < 2 or mapping[0] is None:\n",
    "            continue\n",
    "        plaintext = mapping[0]\n",
    "        if plaintext in counts:\n",
    "            counts[plaintext] += 1\n",
    "        else:\n",
    "            counts[plaintext] = 1\n",
    "        if counts[plaintext] > ext_limits:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Ext Order Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function attempts to find the best ordering for ext_order. The function takes in the cipher vocabular the cipher text, n, the highest ngram number, and weights which is the weighting used in the calculation of the score. The function uses a beam search to search through all enumartions of the vocabulary ordering. The scoring is calculated as the sum 1 to n, the weight n multiplied by the number of continuous ngram for that particular symbol. We start by fixing the first symbol, and then we fix the second. We prune the tree to the 100 best and then continue until we have all symbols in ext order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ext_order_generate(cipher_vocab, cipher_text, n, weights):\n",
    " \n",
    "    sequences = []\n",
    "    sequences.append((\"\",0))\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    unigram = True\n",
    "\n",
    "    cardinality = 0\n",
    "    while cardinality < len(cipher_vocab):\n",
    "        for seq in sequences:\n",
    "            for c in cipher_vocab:\n",
    "                if not in_part_ord(seq, c):\n",
    "                    new_candidate = (seq, c)\n",
    "                    bit_string = generate_bit_string(new_candidate, cipher_text)\n",
    "                    score = 0\n",
    "                    for i in range(0,n):\n",
    "                        ngram_span = get_ngram_span(bit_string, i+1)\n",
    "                        score += weights[i]*len(ngram_span)\n",
    "                    candidates.append((new_candidate, score))\n",
    "            \n",
    "        candidates = histogramPrune(candidates, 100)\n",
    "        sequences = candidates\n",
    "        candidates = []\n",
    "        unigram = False\n",
    "        cardinality+=1\n",
    "    return ord_winner(sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Helper Functions for Ext Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function checks to see if a symbol is in the current partial ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def in_part_ord(part_ord, symbol):\n",
    "    if isinstance(part_ord[1], str):\n",
    "        return in_part_ord(part_ord[0], symbol) or part_ord[1] == symbol\n",
    "    if part_ord[0]:\n",
    "        return in_part_ord(part_ord[0][0], symbol) or part_ord[0][1] == symbol\n",
    "    else:\n",
    "        return False;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds the number of continuous ngrams. IT takes in n and the bit string. Which is of the form \".o.....on..oooon.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ngram_span(bit_string, n):\n",
    "    return {i.span()[0]: i.span()[1] for i in re.finditer(\"o{\" + str(n-1) + \",\" + str(n-1) + \"}n|no{\" + str(n-1) + \",\" + str(n-1) + \"}\", bit_string)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a ext order and flattens it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten_part_ord(part_ord, flattened):\n",
    "\n",
    "    if part_ord:\n",
    "        if isinstance(part_ord[len(part_ord)-1], str):\n",
    "            flattened.append(part_ord[len(part_ord)-1])\n",
    "        if isinstance(part_ord[0], tuple):\n",
    "            return flatten_part_ord(part_ord[0],flattened)\n",
    "    else:\n",
    "        return flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds the winner ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ord_winner(HS):\n",
    "    sequence = []\n",
    "    top = sorted(HS, key=lambda x: x[1], reverse=True)\n",
    "    if len(top) == 0:\n",
    "        return []\n",
    "    flatten_part_ord(top[0], sequence)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates the bit string. It generates a string of the form \".....oooo.ooon...\" o if for a symbol that was already in the partial ordering. n is for the new symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_bit_string(part_ord, cipher_text):\n",
    "\n",
    "    bit_string = \"\"\n",
    "    flattened = []\n",
    "\n",
    "    flatten_part_ord(part_ord[0], flattened)\n",
    "    new_symbol = part_ord[1]\n",
    "\n",
    "    cipher_characters = []\n",
    "    [cipher_characters.append(c) for c in cipher_text]\n",
    "\n",
    "    for character in cipher_characters:\n",
    "        if character == part_ord[1]:\n",
    "            bit_string = bit_string + \"n\"\n",
    "        elif character in flattened:\n",
    "            bit_string = bit_string + \"o\"\n",
    "        else:\n",
    "            bit_string = bit_string + \".\"\n",
    "    return bit_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vf = cipher_desc['vocab']\n",
    "cipher_text = cipher_desc['content']\n",
    "n=6\n",
    "weights = [1.0,1.0,1.0,1.0,2.0,3.0]\n",
    "ext = ext_order_generate(vf, cipher_text, n, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'Ω', '∆', '\\\\', '§', '¢', 'D', 'Q', 'N', 'Ã', 'S', 'K', '“', 'Ç', 'T', '£', '‘', 'M', 'J', 'L', '•', '^', 'ƒ', 'π', 'y', 'æ', 'H', 'F', 'G', '∏', 'Z', '+', '√', 'E', '∞', '—', 'X', '≈', 'µ', 'I', '–', 'W', 'V', 'À', '/', 'u', 'R', 'O', 'P', 'B', '∑', '∫', 'º', 'A']\n",
      "['A', 'º', '∫', '∑', 'B', 'P', 'O', 'R', 'u', '/', 'À', 'V', 'W', '–', 'I', 'µ', '≈', 'X', '—', '∞', 'E', '√', '+', 'Z', '∏', 'G', 'F', 'H', 'æ', 'y', 'π', 'ƒ', '^', '•', 'L', 'J', 'M', '‘', '£', 'T', 'Ç', '“', 'K', 'S', 'Ã', 'N', 'Q', 'D', '¢', '§', '\\\\', '∆', 'Ω', 'j']\n"
     ]
    }
   ],
   "source": [
    "print(ext)\n",
    "ext.reverse()\n",
    "print(ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scoring Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `score` function takes the partial hypothesis phi_prime and converts it into a partial decipherment and corresponding bit string using the helper functions `extract_mappings` and `match_symbols`. Then passes the partial decipherment and bitstring to the ngram language model function `score_bitstring` to return a log prob of phi_prime\n",
    "\n",
    "The `exract_mappings` function recusivily traverses phi_prime to exctract the already established mappings and the appended hypothesis and returns it as a list of tuples\n",
    "\n",
    "The `match_symbols` function takes phi_prime and uses `extract_mappings` to get the list of tuples representing the mappings. Then using the cipher text the function creates a partial decipherment with `_` representing unkown symbols and a corresponding bitstring. The function `returns` a tuple -> `(partial decipherment, bitstring) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def match_symbols(phi_prime, cipher):\n",
    "    \"\"\"\n",
    "    Matches cipher symbols to partial hypothesis mappings and generates a partially deciphered string as well as\n",
    "    a bitstring indicating the locations of the deciphered symbols in the string. \n",
    "\n",
    "    eg.\n",
    "        sequence = (('a',\"A\"), ('e', \"E\"))\n",
    "        cipher = \"GRAEME\"\n",
    "\n",
    "        return \"__a_e_e\" , \"..o.o.o\" \n",
    "    \"\"\"\n",
    "    bitString = \"\"\n",
    "    mappings = {} \n",
    "    sequence = []\n",
    "    extract_mappings(phi_prime, sequence)\n",
    "    for item in sequence: \n",
    "        if item[1] not in mappings.keys():\n",
    "            mappings[item[1]] = item[0]\n",
    "\n",
    "    cipher_characters = []\n",
    "    [cipher_characters.append(c) for c in cipher]\n",
    "    plaintext = \"\"\n",
    "    for character in cipher_characters:\n",
    "        if character in mappings.keys():\n",
    "            bitString = bitString + \"o\"\n",
    "            plaintext = plaintext + mappings[character]\n",
    "        else:\n",
    "            bitString = bitString + \".\"\n",
    "            plaintext = plaintext +\"_\"\n",
    "\n",
    "    return (plaintext, bitString)\n",
    "\n",
    "def score(lm, phi_prime, cipher_txt):\n",
    "    \"\"\"\n",
    "    Uses the ngram model score_bitsting function to return a log prob score of the phi_prime hypothesis and cipher_txt\n",
    "    \"\"\"\n",
    "    hypothesis_string, bitString = match_symbols(phi_prime, cipher_txt)\n",
    "    return lm.score_bitstring(hypothesis_string, bitString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decipherment Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `decipher` function converts the cipher text to a plain text string using the sequence of mappings. `sequence` is a list of tuples which are the mappings found during the beam search.\n",
    "\n",
    "Because the mappings are a list of plaintext => ciphertext tuples, we need to reverse this into dict of ciphertext => plaintext for easy lookup in decipherment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decipher(sequence, cipher):\n",
    "    plaintext = \"\"\n",
    "    bitString =\"\"\n",
    "    mappings = {} \n",
    "    for item in sequence: \n",
    "        if item[1] not in mappings.keys():\n",
    "            mappings[item[1]] = item[0]\n",
    "\n",
    "    cipher_characters = []\n",
    "    [cipher_characters.append(c) for c in cipher]\n",
    "    plaintext = \"\"\n",
    "    for character in cipher_characters:\n",
    "        if character in mappings.keys():\n",
    "            bitString = bitString + \"o\"\n",
    "            plaintext = plaintext + mappings[character]\n",
    "        else:\n",
    "            bitString = bitString + \".\"\n",
    "            plaintext = plaintext +\"_\"\n",
    "\n",
    "    return (plaintext, bitString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Winner Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `winner` function takes all the hypotheses generated from the beam search (`HS`) and returns the best scored hypothesis as a list of mappings.\n",
    "\n",
    "We pick the winner by sorting the hypotheses by their score determined from our `score` function, taking its mapping data, and converting it to a list.\n",
    "\n",
    "If for whatever reason there are no hypotheses, this returns an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def winner(HS):\n",
    "    sequence = []\n",
    "    top = sorted(HS, key=lambda x: x[1], reverse=True)\n",
    "    if len(top) == 0:\n",
    "        return []\n",
    "    extract_mappings(top[0], sequence)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Implementation Efforts and Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Implementing the basic solution took very little time. Most of our time was spent adjusting parameters such as\n",
    "- beam size for kept hypotheses at each beam search stage\n",
    "- `n` for the ngram model\n",
    "- Ext Limit number for mappings\n",
    "\n",
    "We also experimented with the second papers ext_order to improve mapping as an experiment. The results were not as good as those in the paper. We probably need to improve our scoring function to see an improvement in accuracy.\n",
    "\n",
    "Some things we could attempt to implement to improve our decipherment methods:\n",
    "- Implement the second research paper to improve runtime and scoring.\n",
    "- Attempt to use NLM or other model to score hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Solution: Beam search for decipherment of Zodiac 408 cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we initialize the language model that we pass into the beam search for use in the scoring.\n",
    "\n",
    "We are using the ngram model with `n = 6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ngram import LM\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we run our beam search on the provided data:\n",
    "- `Vf` is all of the ciphertext characters from the cipher file.\n",
    "- `Ve` is all of the plaintext chracters from the English language dataset.\n",
    "- `EXT_ORDER`is the sorted list of ciphertext characters by frequency.\n",
    "- `EXT_LIMITS` is the maximum number of mappings that we want to allow for ciphertext chracters to a single plaintext character.\n",
    "- `beam_size` is the number of hypotheses we want to keep at each stage of the beam search.\n",
    "\n",
    "We also pass in the ngram model instantiated above.\n",
    "\n",
    "The result of running this is the highest scored decipherment hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vf = cipher_desc['vocab']\n",
    "ve = plaintxt_desc['vocab']\n",
    "ext_order = [i[0] for i in cipher_desc['frequencies'].most_common(len(cipher_desc['frequencies'])) ]\n",
    "ext_limits = 7\n",
    "beam_size = 5000\n",
    "cipher_text = cipher_desc['content']\n",
    "\n",
    "win = beam_search(lm, vf, ve, ext_order, ext_limits, beam_size, cipher_text)\n",
    "pp.pprint(win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With our obtained decipherment, we now pass that into the `decipher` function and output our decipherment of the Zodiac 408 cipher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decipherment, decrypted_bitstring = decipher(win, cipher_desc['content'])\n",
    "pp.pprint(decipherment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Testing the baseline implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In order to verify that our baseline implementation of the beam search was correct we used a simple caesar cipher as a test. With a 101 character long 1:1 caesar cipher text we are able to acheive 100% accuracy with a beam size of 30. See the details of our testing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caesar_cipher = \"aopzpzhalzaavzllpmdlhjabhssfptwsltlualkaolihzlspuljvyyljasfhukohclhufjohujlhajvtwslapunaopzhzzpnutlua\"\n",
    "caesar_cipher_plaintext = \"thisisatesttoseeifweactuallyimplementedthebaselinecorrectlyandhaveanychanceatcompletingthisassignment\"\n",
    "caesar_cipher_desc = get_statistics(caesar_cipher, cipher = True)\n",
    "\n",
    "test_ve = caesar_cipher_desc['vocab']\n",
    "test_vf = plaintxt_desc['vocab']\n",
    "test_ex_order = [i[0] for i in caesar_cipher_desc['frequencies'].most_common(len(caesar_cipher_desc['frequencies'])) ]\n",
    "test_ext_limits = 1 \n",
    "test_beam_size = 30\n",
    "\n",
    "theWinner = beam_search(lm, test_ve, test_vf, test_ex_order, test_ext_limits, test_beam_size, caesar_cipher) \n",
    "pp.pprint(theWinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_decipherment, test_decrypted_bitstring = decipher(theWinner, caesar_cipher_desc['content'])\n",
    "print(\"-- Decipherment Result -- \")\n",
    "print(test_decipherment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_symbol_error_rate(dec, plaintxt):\n",
    "    correct = 0\n",
    "    if len(plaintxt) == len(dec):\n",
    "        for (d,g) in zip(dec, plaintxt):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(plaintxt)-correct\n",
    "    error = wrong/len(plaintxt)\n",
    "    \n",
    "    return error\n",
    "\n",
    "test_ser = test_symbol_error_rate(test_decipherment, caesar_cipher_plaintext)\n",
    "print(\"decipherment : \" + test_decipherment)\n",
    "print(\"original text: \" + caesar_cipher_plaintext)\n",
    "print(\"---- Results ----\")\n",
    "print('Error: ', test_ser * 100, 'Accuracy: ', (1 - test_ser) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ignore the following cells. They are for grading against the reference decipherment. Based on the clues provided in the decipherment homework description, you can easily find a reasonable reference text online for this cipher text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ATTENTION!\n",
    "For grading purposes only. Don't bundle with the assignment. \n",
    "Make sure '_ref.txt' is removed from the 'data' directory before publishing.\n",
    "\"\"\"\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error\n",
    "    \n",
    "# gold decipherment\n",
    "gold_file = \"data/_ref.txt\"\n",
    "ser = symbol_error_rate(decipherment, gold_file)\n",
    "print('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Best Decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esatttressretorterateartheeaahaereaircresmeaniirystontesearerrsuejessctatiirnotearesrateayehetherssponeinersjrseaeaiosetitasearesearceesotheoetreasstareseayeththninesresttoorarestnttjceheeeyesarrnietariirasasernsttiashetareaissestajirttnaprosresearntaanractorjurehmypasseaistoostessturaseaoererestssotaereesraserotsirescoeratearhssarresstnseatereprryinmtateseisshesareritsaotaianessietreairhasrrereheseattres\n"
     ]
    }
   ],
   "source": [
    "print(decipherment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
